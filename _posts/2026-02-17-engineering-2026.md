---
layout: post
title: "Engineering in 2026 and beyond"
date: 2026-02-17 22:30:00 +0100
categories: ai tech engineering
---
In our team we are talking a lot about what engineering means, and where it's going with all the transformations that are ongoing right now. So maybe because I'm tired of answering the same questions, and also (why not!) to share my vision, I'm summarizing my thoughts.

### As a software engineer
As a software engineer, you try to follow your team's guidelines. Sometimes these guidelines are written down in a document, sometimes agreed upon in weeklies or captured in Confluence pages. Others are simply the unspoken dynamics of a consolidated team that has been working together for a long time.

But even with these rules, there's freedom. A tech lead assumes that not everybody will work the same way or split the code into the same functions. What matters is the shared state of the art: everyone doing their best to achieve it in the same way, within QA boundaries and shared deliverables that keep the whole team aligned.

From a tech lead's point of view, the code a software engineer writes is not what's truly relevant. (Let me clarify: we do have rules and agreements, and as a software engineer, as long as I follow them and stay aligned with the rest of the team, that's fine.) What's relevant for the delivery as an engineer is scalability, performance, security, reusability, and traceability once in production. What matters is that it doesn't introduce regressions and that it's fully aligned with the task and future requirements. It's a shared accountability between the tech lead and the software engineer.

And there's another dynamic worth calling out: debugging. When a software engineer hits a wall — a bug they can't crack, a behavior they can't explain — they don't just sit there forever. They take their time investigating it, and if they can't fix it, they escalate. A tech lead or a senior engineer, not necessarily familiar with that part of the codebase, walks over, pairs up, and together they find the solution. Not because the lead knew that specific code, but because they bring a different perspective, a broader understanding of the system, and fresh eyes on the problem.

**Now replace the word '*software engineer*' with '*AI Agent*'. And replace '*tech lead*' with '*software engineer*'.**

>**This is the software engineering revolution.**

### Engineering in 2026 and beyond

#### Accountability

The game is still exactly the same, but with one key difference. In *legacy* development, the software engineers who wrote the code share responsibility and accountability with the lead. With AI agents writing the code, that shared accountability disappears. **The full weight stays on the engineer**. Imagine you accept a generated service, deploy it, and at 3 AM it leaks customer data through an unvalidated endpoint. Who's accountable? Not the tool that wrote it. You are. You signed off on it. You shipped it. The fact that you didn't write the code changes nothing about who owns the failure. 

There's already a name for what happens when that accountability slips: [workslop](https://www.cnbc.com/2025/09/23/ai-generated-workslop-is-destroying-productivity-and-teams-researchers-say.html) — AI-generated output that looks like work but lacks the substance to actually move things forward. Stanford researchers found it costs organizations millions in lost productivity every year ([HBR](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)). The code equivalent is no different.

#### Guidelines - Rules - Instructions

Just like a tech lead sets the rules and guidelines for the team, the engineer now sets the rules and context for the agents. Agents don't infer your team's conventions from vibes. They need explicit, well-structured instructions — and those instructions need to be the right ones at the right time. Not a massive monolithic document dumped into every session, but efficiently segmented context: small, focused rule files that reference external documentation when depth is needed.

A rule file can be a summary that points to a more extended spec. We usually use this pattern — a short instruction that references deeper documentation for the things that don't come up often. The agent only loads what's relevant to the task at hand. Think of it the same way you'd onboard a new software engineer — you wouldn't hand them the entire Confluence space on day one. You'd point them to what they need for their first tickets and build from there.

The same principle applies to agents, except you have to be deliberate about it every time because they don't carry over what they learned yesterday. And here's the part that's easy to overlook: these rules need to be maintained. Outdated context is worse than no context. If your agent is working from a rule file that references a deprecated API or an old branching strategy, it will confidently produce something that looks right and is completely wrong. Keeping your agent context updated is not a one-time setup — it's an ongoing responsibility, as much a part of your engineering practice as keeping your tests green or your documentation current.

In our team, this isn't theoretical. We've been building and evolving our rules file strategy across the last three projects. Dedicated rule files for integration tests, for data model definitions, for handlers and service logic, for Git commit hooks that enforce JSDoc templates so every piece of generated code is self-documented and justified. Each file is scoped to a specific concern, and each one has been refined based on what worked and what didn't in the previous project.

As a tech lead, and together with the engineers on the team, we're constantly asking the same question: what can we reliably delegate to an agent, and what does the right guardrail look like for that delegation? Every time we find something that can be codified — a pattern, a convention, a quality check — we turn it into a rule file. It's not a finished system. It evolves with every sprint. But the direction is clear: the more precisely you can express your standards in a format an agent can follow, the more you can trust what it produces.

#### Debugging

The debugging dynamic doesn't disappear either — it gets amplified. When an agent gets stuck in a loop, unable to resolve a failing test or an unexpected behavior, the engineer steps in — not necessarily to fix the code, but to redirect the approach, provide context the agent didn't have, or bring in another agent with different instructions and a broader view of the architecture. Sometimes it's the engineer pairing with the agent. Sometimes it's the engineer orchestrating two agents to converge on the problem from different angles. The pattern is exactly what good teams already do: escalate, collaborate, bring fresh perspective. The difference is that instead of waiting for someone to be available, instead of context-switching a senior engineer away from their own work, you spin up that collaboration on demand. The engineer stays in the loop — not as the one writing the fix, but as the one who knows when to pivot, when to reset, and when to bring in reinforcements.

But it's just a matter of time before we're out of that picture too — [Copilot started in December 2025 to bring AI to debugging](https://www.youtube.com/watch?v=EuMThco8hfk).

### The twilight of code

We still have the same responsibilities: making sure that what we deliver is fully aligned with the requirements — scalability, performance, security — all the same concerns as before. **Notice that I haven't mentioned code**. There are articles starting to talk about [write-only code](https://www.heavybit.com/library/article/write-only-code), code that's generated, used, and never read again. This is the direction we're heading. Code is becoming disposable. You can regenerate it, rewrite it from a different prompt, throw it away and start over. But the deliverable — what it does, how it behaves under load, whether it holds up in production — that's permanent. **What matters are the deliverables, not the code.**

I don't know how fast this shift will happen, but remember: there was a time when programmers wrote code on paper and fed it into machines through punch cards. They hand-optimized for specific hardware, memorized instruction sets, agonized over every byte. And then it all became irrelevant. Compilers took over. Higher-level languages abstracted the machine away. Nobody mourned the loss of hand-coded assembly — they just moved up the stack. We're at that same inflection point. Source code is becoming what punch cards were: an implementation detail that the next layer of abstraction will render invisible.

### Own the outcome

So here's the question: are you still defining yourself by the code you write, or by the systems you deliver? If you're an engineer, stop owning the code. Own the outcome. Own the architecture, the reliability, the security, the user experience. The tools that generate code will keep getting better. Your job is to make sure that what ships actually works — and to answer for it when it doesn't. That's not a new responsibility. It's the one you've always had. And as Jelena Perfiljeva [points out](https://boringenterprisenerds.substack.com/p/82-double-joule-abapconf-interviewing?open=false#%C2%A7importance-of-scale), the real challenge was never building something — it was delivering it consistently at scale. The more we delegate to AI, the more that becomes reachable, and faster.

### The Open frontier

#### Long Term Memory

Agents today operate within the boundaries of a single session or a context window. They don't truly remember what they learned last sprint, what architectural decisions were made three months ago, or why a particular pattern was chosen over another. That institutional knowledge still lives in the engineer's head, and bridging that gap is going to be critical. People are already working on it — from open-source projects like [Mem0](https://github.com/mem0ai/mem0) and [memsearch](https://zilliztech.github.io/memsearch/), to enterprise solutions like [AWS AgentCore](https://aws.amazon.com/blogs/machine-learning/building-smarter-ai-agents-agentcore-long-term-memory-deep-dive/) ([docs](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory.html)) — but it's still an open problem.

#### From Stakeholders to AI Pipeline

The other big challenge is upstream: translating business requirements into something agents can actually work with. Today, requirements live scattered across meeting recordings, Google Docs, Figma designs, Slack threads, and half-updated Confluence pages. An agent can write code, but it can't sit in a refinement session and extract what the product owner actually meant. The bridge between business intent and structured, actionable specifications is where frameworks like [Spec Kit](https://github.com/github/spec-kit), [BMAD Method](https://github.com/bmad-code-org/BMAD-METHOD), [Taskmaster](https://github.com/eyaltoledano/claude-task-master), or your own custom approach come in. The real leverage isn't just in generating code — it's in building the pipeline that takes a messy business need and turns it into a structured repository, a well-defined Jira backlog, and clear acceptance criteria that an agent can execute against. That translation layer is the next frontier, and the teams that figure it out first — not just engineering, but the whole organization — will be the ones that truly scale.

### Still figuring it out

I'll be honest — even I fully believe in this shift, and I'm still adapting to it myself. And probably some of my colleagues and folks from other companies aren't fully aligned with this yet — maybe they think I'm crazy. But that's fine. Nobody has it fully figured out yet. We're all somewhere on that curve. What matters is that we're moving in the right direction.

Because at the end of the day, as software engineers, we don't deliver code — we deliver software solutions for business needs.
